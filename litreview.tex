\chapter{Literature Review}

\section{Introduction}
% This introduction is pretty poor, probably best to rewrite once the rest is finished
In this chapter I will give an overview of the existing literature that is appropriate to my project. The chapter is split into two sections. The first section gives a review of Model Driven Engineering and tools that can be used for implementation. The second section investigates software testing methods and ways of assessing the quality of software tests.

\section{Model Driven Engineering}

\subsection{Introduction}
% The Oxford English dictionary defines Model Driven Engineering as... just kidding
Model Driven Engineering is a development methodology that aims to reduce the amount of time spent on code development by building models that can be transformed and used to generate code automatically. Bugs that would normally be in code (through developer error) will no longer be present, as all the code has been generated automatically from a model. Of course this assumes that the model is correct in the first place. Cross-platform implementation overheads are also reduced. The model can remain the same for all platforms, and only the model-to-code program has to be modified for different target platforms. \citep{mdseLano}.

In the 1980's there was a software quality crisis that lead to the search for alternative approaches to developing software. Model Driven Engineering is one solution that was of interest at the time as it provided a way to visually represent a system architecture, and from that generate code automatically. However, the return on investment that companies were expecting from model driven engineering was far too high, causing much disappointment and disillusionment, and for a while the concept was sidelined. More recently, the Object Managment Group (OMG) have promoted and developed a Unified Modeling Language (UML), and tools such as Epsilon have further promoted the use of MDE \citep{mdeHistory}.  \citet{brambillaBook} believes that Model Driven Engineering is now past the `trough of disillusionment' and into the `slope of enlightenment' (see figure \ref{mde_pos}) \\

\begin{figure}
\begin{center}
	\includegraphics[width=4in]{figures/mde_pos.jpg}
\end{center}
\caption{The technology hype cycle according to \citet{brambillaBook}}
\label{mde_pos}
\end{figure}

\subsection{Model}

\begin{figure}
\begin{center}
	\includegraphics[width=4in]{figures/sample_model.jpg}
\end{center}
\caption{A sample model}
%TODO: Create my own model to sample here?
\label{uml_sample}
\end{figure}

A model is a representation of something that abstracts away many details that are not necessary for its use \citep{brambillaBook}. For example, the Utah Teapot \citep{utahTeapot} is a model of a teapot that is rendered by a 3D engine. However, many aspects of the teapot are not considered in its model, as they are not necessary for a simple render. An example is that the lid is not a removable component, because for the purpose of rendering the teapot, the lid never has to be removed. Another example is that the only physical property of the teapot that will be included in the model is it's finish (texture), so that lighting and reflection can be calculated. Other details such as its weight will not be included in the model, because it isnot necessary.

UML (Unified Modeling Language) is a language that is designed specifically for representing models visually. It is ideal for object-oriented design, as it represents classes with boxes and links between classes with lines. Within the boxes there are definitions of the classes (spelling?) methods and fields. In figure \ref{uml_sample}, author is a class that has properties such as name, born, dead. The diagram also shows that there is a connection between author and book.
%TODO: Write about the connection, or update to a better sample model

\subsection{Metamodels}
To have a modeling language, there must be a specification of that language that defines the valid syntax, constraints etc. In the case of UML, the Object Management Group provide a detailed specification \citep{umlSpec} of the language, and we can check that any diagram is a UML diagram by checking it against the UML specification.
%Concrete, Abstract and semantic sections...
A metamodel is the specification of a modeling language, in the form of a model \citep{brambillaBook}. A metamodel could be represented visually or textually, depending on the specification of the metamodeling language. As with many aspects of computer science, the metamodel is just another layer of abstraction, and we can continue to abstract to higher and higher levels. A metametamodel (known as M3) will define the specification of a metamodeling language, and the abstraction can continue as far as is required.

Going back to the example of The Utah Teapot, the metamodel in this case may define that the teapot is made up from interconnected polygons, and specify that each polygon has a location and size given in 3D space. 

\subsubsection{Abstract and Concrete Syntax}

Something about abstract and concrete syntax here

\subsection{Graphical Modeling Framework}

The Eclipse graphical modeling framework (GMF) is part of the Eclipse Graphical Modeling Project \citep{gmpSite}. The Eclipse Wiki \cite{gmpFAQ} defines GMF as:

\begin{quote} Using GMF, you can produce graphical editors for Eclipse. For example, a UML modeling tool, workflow editor, etc. Basically, a graphical editing surface for any domain model in EMF you would like. \end{quote}



\subsection{Epsilon}
To be able to perform Model Driven Engineering, we of course require some tools and languages to build and manipulate models. These tools could be built from scratch for each project, but that would be a waste of time.

Epsilon is a suite of languages and tools that provide all the necessary components to build and manipulate models. Epsilon stands for \textbf{E}xtensible \textbf{P}latform of Integrated \textbf{L}anguages for M\textbf{O}del Ma\textbf{N}agement \citep{epsilonWebsite}. It is part of the Eclipse Modeling Project \citep{ecliplseModelingProjectSite}, and includes tools for each of its languages that integrate with Eclipse. From the Epsilon Website \citep{epsilonWebsite}, the languages that are provided by Epsilon are:

\begin{description}
\item[EOL] Epsilon Object Language is an expression language that is used to create, query and model EMF models.
\item[ETL] Epsilon Transformation Language is a model-to-model transformation language.
\item[EVL] Epsilon Validation Language is a model constraint language.
\item[EGL] Epsilon Generation Language is a model-to-text generation language that can be used to generate code from models.
\item[EWL] Epsilon Wizard Language is similar to ETL, except that ETL performs batch operations whereas EWL works with in-place model transformations based on user selections.
\item[ECL] Epsilon Comparison Language is a model comparison language.
\item[EML] Epsilon Merging Language is used to merge models of diverse metamodels.
\item[Epsilon Flock] A rule
\end{description}

Together these languages provide a powerful framework for model driven engineering.

\subsection{EuGENia}
EuGENia is one of the tools that is included with Epsilon. EuGENia takes an Ecore metamodel specification and generates a GMF editor \citep{eugeniaSite}. From the code in \ref{cha:EugSampCode}, the model editor shown in figure \ref{sampleGmf} is generated by EuGENia.

\begin{figure}
\begin{center}
	\includegraphics[width=4in]{figures/gmfeditor.png}
\end{center}
\caption{A sample gmf editor generated by EuGENia \citep{eugeniaSite}}
\label{sampleGmf}
\end{figure}

The generator editor provides the objects shown on the right hand side of figure \ref{sampleGmf}. These objects are then dragged to the left hand section of the editor by the user, where connections between objects can be intuitively created. 

\subsection{EuGENia Live}

EuGENia Live is a web-based version of EuGENia that removes some of the complexity of getting started with EuGENia. The EuGENia Live Paper \citep{eugeniaLivePaper} describes EuGENia Live as: \begin{quote}... a tool for designing graphical DSLs  \end{quote}

However, unlike EuGENia, EuGENia  Live is a visual tool that allows you to switch back and forth between graphical editing of a DSL and the code for the DSL. Figure \ref{eugeniaLiveGraphical} shows EuGENia Live graphically editing a DSL, and Figure \ref{eugeniaLiveCode} shows the same DSL's code being edited in EuGENia Live.

\begin{figure}[h]
\begin{center}
	\includegraphics[width=4in]{figures/eugenia_live_graphical.png}
\end{center}
\caption{EuGENia Live's Graphical Editor \citep{eugeniaLiveDocumentation}}
\label{eugeniaLiveGraphcal}
\end{figure}

\begin{figure}[h]
\begin{center}
	\includegraphics[width=4in]{figures/eugenia_live_code.png}
\end{center}
\caption{EuGENia Live's Code Editor \citep{eugeniaLiveDocumentation}}
\label{eugeniaLiveCode}
\end{figure}


\section{Quality of Software Testing}
\subsection{Introduction}
Software testing is a crucial part of the development cycle of any serious piece of software. Developers can make changes to code that make it do what they want, but could break another part of the program that uses the same code. Suites of tests can be implemented that \emph{should} notice if a developer breaks the code, but there is the possibility that the correct tests have not been implemented to catch a certain fault.

The Ariane 5 rocket cost \$7 billion to develop, and so of course any software on board would have had test suites to ensure that it did not fail. Unfortunately, 37 seconds after launch, \$500 million of rocket and cargo exploded because of an integer overflow \citep{ariane5}. Despite having software tests, the test `coverage' must have not been sufficient, leading to such a disaster. This is of course an extreme example, but it highlights the need for not only software testing, but good quality software testing.

\subsection{Coverage}

Test sets have a \emph{coverage criterion} that measures how good a collection of sets is \citep{softwareTestingIntro}. According to \citet{softwareTestingIntro}, coverage is defined as:

\begin{quote} Given a set of test requirements $TR$ for a coverage criterion $C$, a test set $T$ satisfies $C$ if and only if for every test requirement $tr$ in $TR$, at least one test $t$ in $T$ exists such that $t$ satisfies $tr$ \end{quote}

In addition to coverage, coverage level is also defined by \citep{softwareTestingIntro} as:

\begin{quote}Given a set of test requirements $TR$ and a test set $T$, the coverage level is simply the ratio of the number of test requirements satisfied by $T$ to the size of $TR$\end{quote}

\subsubsection{Code Coverage}

% ToDo: Find a source other than what Louis told me in lectures...

One approach to determining the quality of a test set is to analyse the number of lines of code that have tests that run them. If all lines of code are executed at least once when all tests have been run, then code coverage is 100\% \citep{something}. This approach is flawed however - having a line of code covered by a test does not necessarily ensure a good quality test set. Many factor can affect the result of a line of code's execution. 

Consider the code in figure \ref{sampleCoverageCode}. Even if a test covers all the lines of code in exampleProcedure, the state of globalVariable will affect the execution path and potentially the outcome of exampleFunction. This means that the tests do not cover all possible states that the program can be in.

\begin{figure}
	\begin{center}
		\includegraphics[width=4in]{figures/code_coverage.png}
	\end{center}
\caption{A sample code snippet}
\label{sampleCoverageCode}
\end{figure}

\subsubsection{Path Coverage}

Another approach to determining the quality of a test set is to consider the path coverage of the code being tested. A section of code can have many paths through it. In the sample code in figure \ref{sampleCoverageCode} there are two obvious paths. The first is through the if statement, the second is to skip the if statement. For a section of code with $n$ inputs, there are potentially $2^n$ code paths \cite{something}. This can of course be problematic, because for any program larger than a few lines of code the numbers of code paths will be very large, quickly getting to the point where it is not feasible to compute all paths, and therefore not possible to check if all paths are covered by a test set.

\subsection{Mutation Testing}

Mutation testing is another approach to determining the quality of a test set. Consider the following line of code:

\begin{lstlisting}
y := 3x + 4 - z;
\end{lstlisting}

This is the fragment of code that we want to check that our test sets sufficiently cover. The code is called the \emph{ground string}. From the ground string, mutant strings are created. These mutant strings are based on the ground string, but have been `mutated' in some way such that they are not the same as the ground string, but still compile \citep{softwareTestingIntro}. Some example mutants might be:

\begin{lstlisting}
y := 3x - 4 - z;
y := 3x - 4 + z;
y := 10x + 6 - i;
\end{lstlisting}

The mutants all compile, but alter the outcome of executing the function. So the quality of a test set can be determined by running the set on each of the mutants and checking how many of the mutants are rejected. The perfect test set would reject all of the mutants \citep{softwareTestingIntro}. The example above is greatly simplified, and in reality it is unlikely that all of the mutants would be caught by the test set.

In addition to being used to determine the quality of test sets, mutation testing (and path coverage and code coverage) can be used to help develop a high quality test set \citep{softwareTestingIntro}.

\subsection{Model Transformation Testing}

EuGENia essentially performs a model transformation - it takes an Ecore metamodel as an input and generates gmf models \citep{eugeniaSite}. 


% Close chapter with testing of model transformations
% Barriers to systematic model transformation testing 2010
% Qualifying input test data for model transformations
% Model transformation testing : Oracle Issue

% 
